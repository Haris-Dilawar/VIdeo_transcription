# -*- coding: utf-8 -*-
"""Transcription.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1orL--SeXyFiwg4P1xYYgPNINOjyXV8KQ

# Video Transcription Techniques

##  First Method
#### Transcribing the Video(Extracting Text)
the code will extract Wav format audio (all format videos supported)
"""

!pip install SpeechRecognition
!pip install pydub
!pip install ffmpeg

#using the AudioSegment class from pydub to load the video file and extract the audio
import speech_recognition as sr
from pydub import AudioSegment
import os

# Load the video file
video = AudioSegment.from_file("videosample.mp4", format="mp4")

#setting the audio to mono, 16kHz, and 16-bit, which is the format that the SpeechRecognition library requires.
audio = video.set_channels(1).set_frame_rate(16000).set_sample_width(2)

#exporting the Audio xD
audio.export("audio.wav", format="wav")

#using the SpeechRecognition library to transcribe it

# Initialize recognizer class (for recognizing the speech)
r = sr.Recognizer()

# Open the audio file
with sr.AudioFile("audio.wav") as source:
    audio_text = r.record(source)

# Recognize the speech in the audio
text = r.recognize_google(audio_text, language='en-US')

print(text)

# Print the transcript
file_name = "transcription.txt"


with open(file_name, "w") as file:
    # Write to the file
    file.write(text)
# Open the file for editing by the user
os.system(f"start {file_name}")

"""# Second method
Using Wave, moviepy and SpeechRecognition
"""

!pip install Wave
!pip install moviepy
!pip install SpeechRecognition

import wave, math, contextlib
import speech_recognition as sr
from moviepy.editor import AudioFileClip

transcribed_audio_file_name = "audio.wav"
video_file_name = "videosample.mp4"

audioclip = AudioFileClip(video_file_name)
audioclip.write_audiofile(transcribed_audio_file_name)

with contextlib.closing(wave.open(transcribed_audio_file_name,'r')) as f:
    frames = f.getnframes()
    rate = f.getframerate()
    duration = frames / float(rate)

total_duration = math.ceil(duration / 60)

print(total_duration)

r = sr.Recognizer()

for i in range(0, total_duration):
    with sr.AudioFile(transcribed_audio_file_name) as source:
        audio = r.record(source,duration=total_duration)
    f = open("transcription.txt", "a")
    f.write(r.recognize_google(audio))
    f.write(" ")
f.close()

file_path = "transcription.txt"
with open(file_path, 'r') as file:
        # Read the content of the file
        file_content = file.read()

print(file_content)

harvard = sr.AudioFile('audio.wav')
with harvard as source:
    audio = r.record(source)



"""# Building Using Whisper
whisper is an amazing SR Ai model developed by OpenAI. It beats google and is an amazing ASR model which supports alot of features such as speech to text, translations, multilingual translations etc
"""

!pip install ffmpeg
!pip install -U openai-whisper

import whisper
model = whisper.load_model("large")
result = model.transcribe("videosample.mp4",language = "en",word_timestamps=True)
print(result["text"])



import whisper
model = whisper.load_model("medium")
result = model.transcribe("videosample.mp4",language = "en",word_timestamps=True)
print(result["text"])

import whisper
model = whisper.load_model("small")
result = model.transcribe("videosample.mp4",language = "en",)
print(result["text"])

"""# Transcribing  with Decipher"""

!pip install git+https://github.com/dsymbol/decipher

!nvidia-smi
!apt update && apt install ffmpeg fonts-open-sans
!pip install git+https://github.com/dsymbol/decipher

from decipher.action import transcribe
import os

def perform_transcription(input_file, output_dir, model="medium", language="en", task="transcribe", subtitle_action=None):
    current_dir = os.getcwd()
    try:
        transcribe(input_file, output_dir if output_dir else "result", model if model else "small", language if language else None, task, subtitle_action if subtitle_action != "None" else None)
    except Exception as e:
        print(f"Error occurred: {e}")
    finally:
        os.chdir(current_dir)

# Example usage:
input_file = "videosample.mp4"
output_directory = "/content"
transcription_model = "medium"
transcription_language = "en"
transcription_task = "transcribe"
subtitle_action = "None"

perform_transcription(input_file, output_directory, transcription_model, transcription_language, transcription_task, subtitle_action)

### for writing subtitles obtained above into the video ..
input = ""
output_dir = "result"
subtitle_file = ""
subtitle_action = "burn"

from decipher.action import subtitle

dir = os.getcwd()

subtitle(
    input,
    output_dir,
    subtitle_file,
    subtitle_action
)

os.chdir(dir)